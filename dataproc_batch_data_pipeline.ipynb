{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33gMAp3zdrGO"
      },
      "source": [
        "Authenticate with Google Cloud CLI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoqoHCopd0Gw",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!gcloud init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVVQEgukKD-"
      },
      "source": [
        "Create credentials file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiGUh4BHkLuL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG8XAiz7eUDa"
      },
      "source": [
        "Create resources on Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUDYvA4qeYdz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Google Cloud Storage Source File (Data Lake)\n",
        "!gsutil mb gs://data_lake_<name>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cK9iBQxN0nFh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Google Cloud Storage Job File\n",
        "!gsutil mb gs://dataproc_job_<name>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pclhGFzuoJhS",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Destination Dataset (Data Warehouse)\n",
        "!bq --location=US mk --dataset \"<project_id>:nyctaxi\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_mAtldl-ezJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Destination Table\n",
        "!bq mk \\\n",
        "--table \\\n",
        "<project_id>:nyctaxi.yellow_tripdata \\\n",
        "vendor_name:STRING,pickup_datetime:STRING,pickup_datetime_day:INTEGER,pickup_datetime_month:INTEGER,pickup_datetime_year:INTEGER,dropoff_datetime:STRING,dropoff_datetime_day:INTEGER,dropoff_datetime_month:INTEGER,dropoff_datetime_year:INTEGER,passenger_count:INT64,trip_distance:FLOAT64,RatecodeID:STRING,store_and_fwd_flag:STRING,PULocationID:INTEGER,DOLocationID:INTEGER,payment_type:STRING,fare_amount:FLOAT64,extra:FLOAT64,mta_tax:FLOAT64,tip_amount:FLOAT64,tolls_amount:FLOAT64,improvement_surcharge:FLOAT64,total_amount:FLOAT64,congestion_surcharge:FLOAT64,airport_fee:FLOAT64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J95FGGIsf6k9"
      },
      "source": [
        "Upload raw data file on data lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WypSBkiggBPI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!gsutil cp \"yellow_tripdata_<date>.parquet\" gs://data_lake_<name>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run Apache Spark jobs we need to create Dataproc cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud dataproc clusters create CLUSTER_NAME \\\n",
        "  --region=REGION \\\n",
        "  --num-workers=NUM_WORKERS \\\n",
        "  --master-machine-type=MASTER_MACHINE_TYPE \\\n",
        "  --worker-machine-type=WORKER_MACHINE_TYPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StUyQNIMCdXW"
      },
      "source": [
        "Install Spark for local development on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt7ZS1_wGgjn"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51m7waZCjyF"
      },
      "source": [
        "Set environment variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdOOq4twHN1K"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctprN-zshqVx"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5A-LDcfhsag"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DateType\n",
        "from pyspark.sql.functions import col, when, dayofmonth, month, year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00-nY39SitRi"
      },
      "source": [
        "Create spark session for your production job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lM0qhNBTYli0",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "56a98548-60e1-4156-e3af-43227c757254",
        "tags": []
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"NYC Taxi\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVFLCehWij_K"
      },
      "source": [
        "Create spark session for development on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR1zLBk1998Z"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEoqLxzLDMD_"
      },
      "source": [
        "Read file and create dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbhOOyRK-ezL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = spark.read.parquet(\"gs://data_lake_<name>/yellow_tripdata_<date>.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh3LTfKMDPrx"
      },
      "source": [
        "Add columns for day, month, year using datetime field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox5zd9N0-ezL"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"tpep_pickup_datetime_day\", dayofmonth(col(\"tpep_pickup_datetime\")))\n",
        "df = df.withColumn(\"tpep_pickup_datetime_month\", month(col(\"tpep_pickup_datetime\")))\n",
        "df = df.withColumn(\"tpep_pickup_datetime_year\", year(col(\"tpep_pickup_datetime\")))\n",
        "df = df.withColumn(\"tpep_dropoff_datetime_day\", dayofmonth(col(\"tpep_dropoff_datetime\")))\n",
        "df = df.withColumn(\"tpep_dropoff_datetime_month\", month(col(\"tpep_dropoff_datetime\")))\n",
        "df = df.withColumn(\"tpep_dropoff_datetime_year\", year(col(\"tpep_dropoff_datetime\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ4OoAHSL28F"
      },
      "source": [
        "Change values of columns with numeric values to their actual values. This information is provided in data dictionary of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr60SCV2-ezL"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"VendorID\",\n",
        "    when(col(\"VendorID\") == 1, \"Creative Mobile Technologies\")\n",
        "    .when(col(\"VendorID\") == 2, \"VeriFone Inc\")\n",
        "    .otherwise(col(\"VendorID\"))\n",
        ")\n",
        "\n",
        "df = df.withColumn(\"RateCodeID\",\n",
        "    when(col(\"RateCodeID\") == 1, \"Standard rate\")\n",
        "    .when(col(\"RateCodeID\") == 2, \"JFK\")\n",
        "    .when(col(\"RateCodeID\") == 3, \"Newark\")\n",
        "    .when(col(\"RateCodeID\") == 4, \"Nassau or Westchester\")\n",
        "    .when(col(\"RateCodeID\") == 5, \"Negotiated fare\")\n",
        "    .when(col(\"RateCodeID\") == 6, \"Group ride\")\n",
        "    .otherwise(col(\"RateCodeID\"))\n",
        ")\n",
        "\n",
        "df = df.withColumn(\"Store_and_fwd_flag\",\n",
        "    when(col(\"Store_and_fwd_flag\") == \"Y\" ,\"store and forward trip\")\n",
        "    .when(col(\"Store_and_fwd_flag\") == \"N\", \"not a store and forward trip\")\n",
        "    .otherwise(col(\"Store_and_fwd_flag\"))\n",
        ")\n",
        "\n",
        "df = df.withColumn(\"Payment_type\",\n",
        "    when(col(\"Payment_type\") == 1, \"Credit card\")\n",
        "    .when(col(\"Payment_type\") == 2, \"Cash\")\n",
        "    .when(col(\"Payment_type\") == 3, \"No charge\")\n",
        "    .when(col(\"Payment_type\") == 4, \"Dispute\")\n",
        "    .when(col(\"Payment_type\") == 5, \"Unknown\")\n",
        "    .when(col(\"Payment_type\") == 6, \"Voided trip\")\n",
        "    .otherwise(col(\"Payment_type\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MIcudGQL856"
      },
      "source": [
        "Change data type of columns. The default datatype inferred by spark can be inaccurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDfSRsOw-ezL"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn(\"tpep_pickup_datetime\", col(\"tpep_pickup_datetime\").cast(StringType()))\n",
        "df = df.withColumn(\"tpep_dropoff_datetime\", col(\"tpep_dropoff_datetime\").cast(StringType()))\n",
        "df = df.withColumn(\"passenger_count\", col(\"passenger_count\").cast(IntegerType()))\n",
        "df = df.withColumn(\"trip_distance\", col(\"trip_distance\").cast(FloatType()))\n",
        "df = df.withColumn(\"fare_amount\", col(\"fare_amount\").cast(FloatType()))\n",
        "df = df.withColumn(\"extra\", col(\"extra\").cast(FloatType()))\n",
        "df = df.withColumn(\"mta_tax\", col(\"mta_tax\").cast(FloatType()))\n",
        "df = df.withColumn(\"tip_amount\", col(\"tip_amount\").cast(FloatType()))\n",
        "df = df.withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(FloatType()))\n",
        "df = df.withColumn(\"improvement_surcharge\", col(\"improvement_surcharge\").cast(FloatType()))\n",
        "df = df.withColumn(\"total_amount\", col(\"total_amount\").cast(FloatType()))\n",
        "df = df.withColumn(\"congestion_surcharge\", col(\"congestion_surcharge\").cast(FloatType()))\n",
        "df = df.withColumn(\"Airport_fee\", col(\"Airport_fee\").cast(FloatType()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqH-6H_xL9v6"
      },
      "source": [
        "Rename columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8Wk5JO3-ezL",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = df.withColumnRenamed('VendorID', 'vendor_name')\n",
        "df = df.withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime')\n",
        "df = df.withColumnRenamed('tpep_pickup_datetime_day', 'pickup_datetime_day')\n",
        "df = df.withColumnRenamed('tpep_pickup_datetime_month', 'pickup_datetime_month')\n",
        "df = df.withColumnRenamed('tpep_pickup_datetime_year', 'pickup_datetime_year')\n",
        "df = df.withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')\n",
        "df = df.withColumnRenamed('tpep_dropoff_datetime_day', 'dropoff_datetime_day')\n",
        "df = df.withColumnRenamed('tpep_dropoff_datetime_month', 'dropoff_datetime_month')\n",
        "df = df.withColumnRenamed('tpep_dropoff_datetime_year', 'dropoff_datetime_year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMcypg6C-ezL"
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbXVSu18MIk-"
      },
      "source": [
        "Change order of columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSMNkh-i-ezM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "new_column_order = [\"vendor_name\",\n",
        "\"pickup_datetime\",\n",
        "\"pickup_datetime_day\",\n",
        "\"pickup_datetime_month\",\n",
        "\"pickup_datetime_year\",\n",
        "\"dropoff_datetime\",\n",
        "\"dropoff_datetime_day\",\n",
        "\"dropoff_datetime_month\",\n",
        "\"dropoff_datetime_year\",\n",
        "\"passenger_count\",\n",
        "\"trip_distance\",\n",
        "\"RatecodeID\",\n",
        "\"store_and_fwd_flag\",\n",
        "\"PULocationID\",\n",
        "\"DOLocationID\",\n",
        "\"payment_type\",\n",
        "\"fare_amount\",\n",
        "\"extra\",\n",
        "\"mta_tax\",\n",
        "\"tip_amount\",\n",
        "\"tolls_amount\",\n",
        "\"improvement_surcharge\",\n",
        "\"total_amount\",\n",
        "\"congestion_surcharge\",\n",
        "\"airport_fee\"]\n",
        "df = df.select(*new_column_order)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owiFNiff-ezM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37KfbbUyMsjP"
      },
      "source": [
        "Load data into BigQuery table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XD-55mfK-ezM"
      },
      "outputs": [],
      "source": [
        "# Use the Cloud Storage bucket for temporary BigQuery export data used by the connector.\n",
        "bucket = \"data_lake_<project_id>\"\n",
        "spark.conf.set('temporaryGcsBucket', bucket)\n",
        "\n",
        "df.write.format('bigquery') \\\n",
        "  .option('table', 'nyctaxi.yellow_tripdata11') \\\n",
        "  .mode('append') \\\n",
        "  .save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufl6U4hdPjSC"
      },
      "source": [
        "Create a python file and add all the code in it. Upload pyspark python file to dataproc job bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2MJhBA8-ezM",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!gsutil cp dataproc-job.py gs://dataproc_job_<project_id>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH44NLUDxVHS",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "source": [
        "\n",
        "Submit job to Dataproc cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjgMMQ6r8r6J",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!gcloud dataproc jobs submit pyspark \\\n",
        "    gs://dataproc_job_<project_id>/dataproc-job.py \\\n",
        "    --cluster <cluster_name>  \\\n",
        "    --region us-central1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
